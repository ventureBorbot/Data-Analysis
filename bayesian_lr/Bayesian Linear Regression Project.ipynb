{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction:-Bayesian-Linear-Regression-Project\" data-toc-modified-id=\"Introduction:-Bayesian-Linear-Regression-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction: Bayesian Linear Regression Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dataset</a></span></li></ul></li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-Data-and-Examine\" data-toc-modified-id=\"Read-in-Data-and-Examine-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Read in Data and Examine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describe-for-Numerical-Columns\" data-toc-modified-id=\"Describe-for-Numerical-Columns-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Describe for Numerical Columns</a></span></li><li><span><a href=\"#Value-Counts-for-Categorical-Columns\" data-toc-modified-id=\"Value-Counts-for-Categorical-Columns-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Value Counts for Categorical Columns</a></span></li><li><span><a href=\"#Distribution-of-Grades\" data-toc-modified-id=\"Distribution-of-Grades-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Distribution of Grades</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grade-Distribution-by-Different-Categorical-Variables\" data-toc-modified-id=\"Grade-Distribution-by-Different-Categorical-Variables-2.1.3.1\"><span class=\"toc-item-num\">2.1.3.1&nbsp;&nbsp;</span>Grade Distribution by Different Categorical Variables</a></span></li></ul></li><li><span><a href=\"#Grade-Percentiles\" data-toc-modified-id=\"Grade-Percentiles-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Grade Percentiles</a></span></li></ul></li></ul></li><li><span><a href=\"#Variable-Correlations-with-Final-Grade\" data-toc-modified-id=\"Variable-Correlations-with-Final-Grade-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Variable Correlations with Final Grade</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numerical-Correlations\" data-toc-modified-id=\"Numerical-Correlations-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Numerical Correlations</a></span></li><li><span><a href=\"#Categorical-Correlations-using-One-Hot-Encoding\" data-toc-modified-id=\"Categorical-Correlations-using-One-Hot-Encoding-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Categorical Correlations using One-Hot Encoding</a></span></li></ul></li><li><span><a href=\"#Select-6-Most-Correlated-Variables-with-Final-Score\" data-toc-modified-id=\"Select-6-Most-Correlated-Variables-with-Final-Score-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Select 6 Most Correlated Variables with Final Score</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Rename-Variables\" data-toc-modified-id=\"Rename-Variables-4.0.0.1\"><span class=\"toc-item-num\">4.0.0.1&nbsp;&nbsp;</span>Rename Variables</a></span></li></ul></li></ul></li><li><span><a href=\"#Pairs-Plot-of-Selected-Variables\" data-toc-modified-id=\"Pairs-Plot-of-Selected-Variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Pairs Plot of Selected Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Selected-Variables-Distribution-by-Relation-to-Median\" data-toc-modified-id=\"Selected-Variables-Distribution-by-Relation-to-Median-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Selected Variables Distribution by Relation to Median</a></span></li></ul></li></ul></li><li><span><a href=\"#Establish-Benchmarks\" data-toc-modified-id=\"Establish-Benchmarks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Establish Benchmarks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Baseline\" data-toc-modified-id=\"Naive-Baseline-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Naive Baseline</a></span></li></ul></li><li><span><a href=\"#Standard-Machine-Learning-Models\" data-toc-modified-id=\"Standard-Machine-Learning-Models-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Standard Machine Learning Models</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Visual-Comparison-of-Models\" data-toc-modified-id=\"Visual-Comparison-of-Models-5.2.0.1\"><span class=\"toc-item-num\">5.2.0.1&nbsp;&nbsp;</span>Visual Comparison of Models</a></span></li></ul></li></ul></li><li><span><a href=\"#Formula-from-Ordinary-Least-Squares-Linear-Regression\" data-toc-modified-id=\"Formula-from-Ordinary-Least-Squares-Linear-Regression-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Formula from Ordinary Least Squares Linear Regression</a></span></li></ul></li><li><span><a href=\"#Implementing-Bayesian-Linear-Regression\" data-toc-modified-id=\"Implementing-Bayesian-Linear-Regression-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Implementing Bayesian Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Model-in-PyMC3-and-Sample-from-Posterior\" data-toc-modified-id=\"Create-Model-in-PyMC3-and-Sample-from-Posterior-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Create Model in PyMC3 and Sample from Posterior</a></span></li></ul></li><li><span><a href=\"#Examine-Bayesian-Linear-Regression-Results\" data-toc-modified-id=\"Examine-Bayesian-Linear-Regression-Results-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Examine Bayesian Linear Regression Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Traceplot-of-All-Samples\" data-toc-modified-id=\"Traceplot-of-All-Samples-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Traceplot of All Samples</a></span></li><li><span><a href=\"#Interpretations-of-Weights\" data-toc-modified-id=\"Interpretations-of-Weights-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Interpretations of Weights</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Formula-from-Bayesian-Inference-using-Mean-of-Parameters\" data-toc-modified-id=\"Linear-Formula-from-Bayesian-Inference-using-Mean-of-Parameters-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Linear Formula from Bayesian Inference using Mean of Parameters</a></span></li></ul></li><li><span><a href=\"#Evaluate-Bayesian-Model-Using-Mean-of-Model-Parameters\" data-toc-modified-id=\"Evaluate-Bayesian-Model-Using-Mean-of-Model-Parameters-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Evaluate Bayesian Model Using Mean of Model Parameters</a></span></li></ul></li><li><span><a href=\"#Make-Predictions-from-Model\" data-toc-modified-id=\"Make-Predictions-from-Model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Make Predictions from Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-Observations\" data-toc-modified-id=\"Test-Observations-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Test Observations</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Predictions-for-New-Observation\" data-toc-modified-id=\"Predictions-for-New-Observation-8.1.0.1\"><span class=\"toc-item-num\">8.1.0.1&nbsp;&nbsp;</span>Predictions for New Observation</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Model-Variable-Effects\" data-toc-modified-id=\"Model-Variable-Effects-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Model Variable Effects</a></span></li><li><span><a href=\"#Different-Likelihood-Prior-Distribution\" data-toc-modified-id=\"Different-Likelihood-Prior-Distribution-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Different Likelihood Prior Distribution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-Model-and-Perform-Inference\" data-toc-modified-id=\"Build-Model-and-Perform-Inference-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Build Model and Perform Inference</a></span></li><li><span><a href=\"#Test-the-Model\" data-toc-modified-id=\"Test-the-Model-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Test the Model</a></span></li><li><span><a href=\"#New-Observation-Predictions\" data-toc-modified-id=\"New-Observation-Predictions-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>New Observation Predictions</a></span></li></ul></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Bayesian Linear Regression Project\n",
    "\n",
    "In this notebook, we will implement a complete machine learning project, focusing on Bayesian Inference methods, in particular, Bayesian Linear Regression. We will go through the entire machine learning process, cleaning the data, exploring it to find trends, establishing a baseline model, evaluating several machine learning approaches for comparisons, implementing Bayesian Linear Regression, interpreting the results, and presenting the results. Let's get started!\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using data on student grades collected from a Portuguese secondary (high) school. This data is from the [UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/student+performance#), a great collection of datasets for model testing. The data includes academic and personal characteristics of the students as well as final grades. The objective is to predict the final grade from the student information which makes this a __supervised, regression task__. We have a set of training data with known labels, and we want the model to learn a mapping from the features (explanatory variables) to the target (the label) in this case the final grade. It is a regression task because the final grade is a continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    " \n",
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 9)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Scipy helper functions\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard ML Models for comparison\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Splitting data into training/testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "# Distributions\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC3 for Bayesian Inference\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data and Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in class scores\n",
    "df = pd.read_csv('data/student-mat.csv')\n",
    "\n",
    "# Filter out grades that were 0\n",
    "df = df[~df['G3'].isin([0, 1])]\n",
    "\n",
    "df = df.rename(columns={'G3': 'Grade'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe for Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts for Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for categorical columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        print('\\nColumn Name:', col,)\n",
    "        print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Grade'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of grades\n",
    "plt.bar(df['Grade'].value_counts().index, \n",
    "        df['Grade'].value_counts().values,\n",
    "         fill = 'navy', edgecolor = 'k', width = 1)\n",
    "plt.xlabel('Grade'); plt.ylabel('Count'); plt.title('Distribution of Final Grades');\n",
    "plt.xticks(list(range(5, 20)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade Distribution by Different Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution by address\n",
    "sns.kdeplot(df.loc[df['address'] == 'U', 'Grade'], label = 'Urban', shade = True)\n",
    "sns.kdeplot(df.loc[df['address'] == 'R', 'Grade'], label = 'Rural', shade = True)\n",
    "plt.xlabel('Grade'); plt.ylabel('Density'); plt.title('Density Plot of Final Grades by Location');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution by Guardian\n",
    "sns.kdeplot(df.loc[df['guardian'] == 'father', 'Grade'], label = 'Father', shade = True)\n",
    "sns.kdeplot(df.loc[df['guardian'] == 'mother', 'Grade'], label = 'Mother', shade = True)\n",
    "sns.kdeplot(df.loc[df['guardian'] == 'other', 'Grade'], label = 'Other', shade = True)\n",
    "plt.xlabel('Grade'); plt.ylabel('Density'); plt.title('Density Plot of Final Grades by Guardian');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution by internet\n",
    "sns.kdeplot(df.loc[df['internet'] == 'yes', 'Grade'], label = 'Internet', shade = True)\n",
    "sns.kdeplot(df.loc[df['internet'] == 'no', 'Grade'], label = 'No Internet', shade = True)\n",
    "plt.xlabel('Grade'); plt.ylabel('Density'); plt.title('Density Plot of Final Grades by Internet Access');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution by school\n",
    "sns.kdeplot(df.loc[df['school'] == 'GP', 'Grade'], label = 'GP', shade = True)\n",
    "sns.kdeplot(df.loc[df['school'] == 'MS', 'Grade'], label = 'MS', shade = True)\n",
    "plt.xlabel('Grade'); plt.ylabel('Count'); plt.title('Distribution of Final Grades by School');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution of schools by address\n",
    "schools = df.groupby(['school'])['address'].value_counts()\n",
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentile for grades\n",
    "df['percentile'] = df['Grade'].apply(lambda x: percentileofscore(df['Grade'], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentiles for grades\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(df['Grade'], df['percentile'], 'o')\n",
    "plt.xticks(range(0, 20, 2), range(0, 20, 2))\n",
    "plt.xlabel('Score'); plt.ylabel('Percentile'); plt.title('Grade Percentiles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50th percentile score:', np.min(df.loc[df['percentile'] > 50, 'Grade']))\n",
    "print('Minimum Score needed for 90th percentile:', np.min(df.loc[df['percentile'] > 90, 'Grade']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Correlations with Final Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations of numerical values\n",
    "df.corr()['Grade'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Correlations using One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only categorical variables\n",
    "category_df = df.select_dtypes('object')\n",
    "# One hot encode the variables\n",
    "dummy_df = pd.get_dummies(category_df)\n",
    "# Put the grade back in the dataframe\n",
    "dummy_df['Grade'] = df['Grade']\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations in one-hot encoded dataframe\n",
    "dummy_df.corr()['Grade'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select 6 Most Correlated Variables with Final Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a dataframe, finds the most correlated variables with the\n",
    "# grade and returns training and testing datasets\n",
    "def format_data(df):\n",
    "    # Targets are final grade of student\n",
    "    labels = df['Grade']\n",
    "    \n",
    "    # Drop the school and the grades from features\n",
    "    df = df.drop(columns=['school', 'G1', 'G2', 'percentile'])\n",
    "    \n",
    "    # One-Hot Encoding of Categorical Variables\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Find correlations with the Grade\n",
    "    most_correlated = df.corr().abs()['Grade'].sort_values(ascending=False)\n",
    "    \n",
    "    # Maintain the top 6 most correlation features with Grade\n",
    "    most_correlated = most_correlated[:8]\n",
    "    \n",
    "    df = df.ix[:, most_correlated.index]\n",
    "    df = df.drop(columns = 'higher_no')\n",
    "    \n",
    "    # Split into training/testing sets with 25% split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, labels, \n",
    "                                                        test_size = 0.25,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = format_data(df)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables in train and teste\n",
    "X_train = X_train.rename(columns={'higher_yes': 'higher_edu', \n",
    "                                  'Medu': 'mother_edu',\n",
    "                                  'Fedu': 'father_edu'})\n",
    "\n",
    "X_test = X_test.rename(columns={'higher_yes': 'higher_edu', \n",
    "                                  'Medu': 'mother_edu',\n",
    "                                  'Fedu': 'father_edu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairs Plot of Selected Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate correlation coefficient\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 24)\n",
    "    \n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.5, as_cmap=True)\n",
    "\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "# Pair grid set up\n",
    "g = sns.PairGrid(X_train)\n",
    "\n",
    "# Scatter plot on the upper triangle\n",
    "g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# Distribution on the diagonal\n",
    "g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# Density Plot and Correlation coefficients on the lower triangle\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "g.map_lower(corrfunc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relation to the median grade column\n",
    "X_plot = X_train.copy()\n",
    "X_plot['relation_median'] = (X_plot['Grade'] >= 12)\n",
    "X_plot['relation_median'] = X_plot['relation_median'].replace({True: 'above', False: 'below'})\n",
    "X_plot = X_plot.drop(columns='Grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Variables Distribution by Relation to Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "# Plot the distribution of each variable colored\n",
    "# by the relation to the median grade\n",
    "for i, col in enumerate(X_plot.columns[:-1]):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    subset_above = X_plot[X_plot['relation_median'] == 'above']\n",
    "    subset_below = X_plot[X_plot['relation_median'] == 'below']\n",
    "    sns.kdeplot(subset_above[col], label = 'Above Median', color = 'green')\n",
    "    sns.kdeplot(subset_below[col], label = 'Below Median', color = 'red')\n",
    "    plt.legend(); plt.title('Distribution of %s' % col)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "For this regression task, we will use two standard metrics:\n",
    "\n",
    "* Mean Absolute Error (MAE): Average of the absolute value of the difference between predictions and the true values\n",
    "* Root Mean Squared Error (RMSE): The square root of the average of the squared differences between the predictions and the true values.\n",
    "\n",
    "The mean absolute error is more interpretable, but the root mean squared error penalizes larger errors more heavily. Either one may be appropriate depending on the situation. \n",
    "[Here is a discussion](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mae and rmse\n",
    "def evaluate_predictions(predictions, true):\n",
    "    mae = np.mean(abs(predictions - true))\n",
    "    rmse = np.sqrt(np.mean((predictions - true) ** 2))\n",
    "    \n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Baseline\n",
    "\n",
    "For a regression task, a simple naive baseline is to guess the median value on the training set for all testing cases. If our machine learning model cannot better this simple baseline, then perhaps we should try a different approach! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive baseline is the median\n",
    "median_pred = X_train['Grade'].median()\n",
    "median_preds = [median_pred for _ in range(len(X_test))]\n",
    "true = X_test['Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the naive baseline metrics\n",
    "mb_mae, mb_rmse = evaluate_predictions(median_preds, true)\n",
    "print('Median Baseline  MAE: {:.4f}'.format(mb_mae))\n",
    "print('Median Baseline RMSE: {:.4f}'.format(mb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate several ml models by training on training set and testing on testing set\n",
    "def evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Names of models\n",
    "    model_name_list = ['Linear Regression', 'ElasticNet Regression',\n",
    "                      'Random Forest', 'Extra Trees', 'SVM',\n",
    "                       'Gradient Boosted', 'Baseline']\n",
    "    X_train = X_train.drop(columns='Grade')\n",
    "    X_test = X_test.drop(columns='Grade')\n",
    "    \n",
    "    # Instantiate the models\n",
    "    model1 = LinearRegression()\n",
    "    model2 = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "    model3 = RandomForestRegressor(n_estimators=50)\n",
    "    model4 = ExtraTreesRegressor(n_estimators=50)\n",
    "    model5 = SVR(kernel='rbf', degree=3, C=1.0, gamma='auto')\n",
    "    model6 = GradientBoostingRegressor(n_estimators=20)\n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns=['mae', 'rmse'], index = model_name_list)\n",
    "    \n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate([model1, model2, model3, model4, model5, model6]):\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        mae = np.mean(abs(predictions - y_test))\n",
    "        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
    "        \n",
    "        # Insert results into the dataframe\n",
    "        model_name = model_name_list[i]\n",
    "        results.ix[model_name, :] = [mae, rmse]\n",
    "    \n",
    "    # Median Value Baseline Metrics\n",
    "    baseline = np.median(y_train)\n",
    "    baseline_mae = np.mean(abs(baseline - y_test))\n",
    "    baseline_rmse = np.sqrt(np.mean((baseline - y_test) ** 2))\n",
    "    \n",
    "    results.ix['Baseline', :] = [baseline_mae, baseline_rmse]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12, 8)\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "# Root mean squared error\n",
    "ax =  plt.subplot(1, 2, 1)\n",
    "results.sort_values('mae', ascending = True).plot.bar(y = 'mae', color = 'b', ax = ax)\n",
    "plt.title('Model Mean Absolute Error'); plt.ylabel('MAE');\n",
    "\n",
    "# Median absolute percentage error\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "results.sort_values('rmse', ascending = True).plot.bar(y = 'rmse', color = 'r', ax = ax)\n",
    "plt.title('Model Root Mean Squared Error'); plt.ylabel('RMSE');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Gradient Boosted regressor is {:0.2f}% better than the baseline.'.format(\n",
    "    (100 * abs(results.loc['Gradient Boosted', 'mae'] - results.loc['Baseline', 'mae'])) / results.loc['Baseline', 'mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula from Ordinary Least Squares Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train.drop(columns='Grade'), y_train)\n",
    "\n",
    "ols_formula = 'Grade = %0.2f +' % lr.intercept_\n",
    "for i, col in enumerate(X_train.columns[1:]):\n",
    "    ols_formula += ' %0.2f * %s +' % (lr.coef_[i], col)\n",
    "    \n",
    "' '.join(ols_formula.split(' ')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for Bayesian Linear Regression (follows R formula syntax\n",
    "formula = 'Grade ~ ' + ' + '.join(['%s' % variable for variable in X_train.columns[1:]])\n",
    "formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model in PyMC3 and Sample from Posterior\n",
    "\n",
    "We now build the model using the formula defined above and a normal distribution for the data likelihood. Then, we let a Markov Chain Monte Carlo algorithm draw samples from the posterior to approximate the posterior for each of the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context for the model\n",
    "with pm.Model() as normal_model:\n",
    "    \n",
    "    # The prior for the model parameters will be a normal distribution\n",
    "    family = pm.glm.families.Normal()\n",
    "    \n",
    "    # Creating the model requires a formula and data (and optionally a family)\n",
    "    pm.GLM.from_formula(formula, data = X_train, family = family)\n",
    "    \n",
    "    # Perform Markov Chain Monte Carlo sampling\n",
    "    normal_trace = pm.sample(draws=2000, chains = 2, tune = 500, njobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Bayesian Linear Regression Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traceplot of All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the trace with a vertical line at the mean of the trace\n",
    "def plot_trace(trace):\n",
    "    # Traceplot with vertical lines at the mean value\n",
    "    ax = pm.traceplot(trace, figsize=(14, len(trace.varnames)*1.8),\n",
    "                      lines={k: v['mean'] for k, v in pm.df_summary(trace).iterrows()})\n",
    "    \n",
    "    matplotlib.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Labels with the median value\n",
    "    for i, mn in enumerate(pm.df_summary(trace)['mean']):\n",
    "        ax[i, 0].annotate('{:0.2f}'.format(mn), xy = (mn, 0), xycoords = 'data', size = 8,\n",
    "                          xytext = (-18, 18), textcoords = 'offset points', rotation = 90,\n",
    "                          va = 'bottom', fontsize = 'large', color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trace(normal_trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(normal_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left side of the traceplot is the marginal posterior: the values for the variable are on the x-axis with the probability for the variable (as determined by sampling) on the y-axis. The different colored lines indicate that we performed two chains of Markov Chain Monte Carlo. From the left side we can see that there is a range of values for each weight. The right side shows the different sample values drawn as the sampling process runs. \n",
    "\n",
    "Another method built into PyMC3 for examinig trace results is the forestplot which shows the distribution of each sampled parameter. This allows us to see the uncertainty in each sample. The forestplot is easily constructed from the trace using `pm.forestplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(normal_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the forest plot we can see the most likely value of the parameter (the dot) as well as the 95% credible interval for the parameter. The `intercept` and `higher_edu` have larger uncertainty compared to the other variables. \n",
    "\n",
    "Another built in plotting method in PyMC3 is the posterior distribution of all the model parameters. These histograms allow us to see how the model result is a distribution for the parameters rather than a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(normal_trace, figsize = (14, 14), text_size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the mean variable weight from the trace\n",
    "for variable in normal_trace.varnames:\n",
    "    print('Variable: {:15} Mean weight in model: {:.4f}'.format(variable, \n",
    "                                                                np.mean(normal_trace[variable])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations of Weights\n",
    "\n",
    "Based on the sign and location of the weights, we can make the following inferences regarding the features in our dataset:\n",
    "\n",
    "* Previous class failures are negatively related to the students final grade\n",
    "* Higher education ambitions are positively related to the students grade\n",
    "* The mother's and father's education levels are positively related to the students final grade\n",
    "* Studying time per week is positively related to the students final grade\n",
    "* Absences are negatively related to the students final grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.df_summary(normal_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Formula from Bayesian Inference using Mean of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_formula = 'Grade = '\n",
    "for variable in normal_trace.varnames:\n",
    "    model_formula += ' %0.2f * %s +' % (np.mean(normal_trace[variable]), variable)\n",
    "\n",
    "' '.join(model_formula.split(' ')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Bayesian Model Using Mean of Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the MCMC trace and compare to ml models\n",
    "def evaluate_trace(trace, X_train, X_test, y_train, y_test, model_results):\n",
    "    \n",
    "    # Dictionary of all sampled values for each parameter\n",
    "    var_dict = {}\n",
    "    for variable in trace.varnames:\n",
    "        var_dict[variable] = trace[variable]\n",
    "        \n",
    "    # Results into a dataframe\n",
    "    var_weights = pd.DataFrame(var_dict)\n",
    "    \n",
    "    # Means for all the weights\n",
    "    var_means = var_weights.mean(axis=0)\n",
    "    \n",
    "    # Create an intercept column\n",
    "    X_test['Intercept'] = 1\n",
    "    \n",
    "    # Align names of the test observations and means\n",
    "    names = X_test.columns[1:]\n",
    "    X_test = X_test.ix[:, names]\n",
    "    var_means = var_means[names]\n",
    "    \n",
    "    # Calculate estimate for each test observation using the average weights\n",
    "    results = pd.DataFrame(index = X_test.index, columns = ['estimate'])\n",
    "\n",
    "    for row in X_test.iterrows():\n",
    "        results.ix[row[0], 'estimate'] = np.dot(np.array(var_means), np.array(row[1]))\n",
    "        \n",
    "    # Metrics \n",
    "    actual = np.array(y_test)\n",
    "    errors = results['estimate'] - actual\n",
    "    mae = np.mean(abs(errors))\n",
    "    rmse = np.sqrt(np.mean(errors ** 2))\n",
    "    \n",
    "    print('Model  MAE: {:.4f}\\nModel RMSE: {:.4f}'.format(mae, rmse))\n",
    "    \n",
    "    # Add the results to the comparison dataframe\n",
    "    model_results.ix['Bayesian LR', :] = [mae, rmse]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot median absolute percentage error of all models\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    model_results.sort_values('mae', ascending = True).plot.bar(y = 'mae', color = 'r', ax = ax)\n",
    "    plt.title('Model Mean Absolute Error Comparison'); plt.ylabel('MAE'); \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot root mean squared error of all models\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    model_results.sort_values('rmse', ascending = True).plot.bar(y = 'rmse', color = 'b', ax = ax)\n",
    "    plt.title('Model RMSE Comparison'); plt.ylabel('RMSE')\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results = evaluate_trace(normal_trace, X_train, X_test, y_train, y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions from Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new prediction from the test set and compare to actual value\n",
    "def test_model(trace, test_observation):\n",
    "    \n",
    "    # Print out the test observation data\n",
    "    print('Test Observation:')\n",
    "    print(test_observation)\n",
    "    var_dict = {}\n",
    "    for variable in trace.varnames:\n",
    "        var_dict[variable] = trace[variable]\n",
    "\n",
    "    # Results into a dataframe\n",
    "    var_weights = pd.DataFrame(var_dict)\n",
    "    \n",
    "    # Standard deviation of the likelihood\n",
    "    sd_value = var_weights['sd'].mean()\n",
    "\n",
    "    # Actual Value\n",
    "    actual = test_observation['Grade']\n",
    "    \n",
    "    # Add in intercept term\n",
    "    test_observation['Intercept'] = 1\n",
    "    test_observation = test_observation.drop('Grade')\n",
    "    \n",
    "    # Align weights and test observation\n",
    "    var_weights = var_weights[test_observation.index]\n",
    "\n",
    "    # Means for all the weights\n",
    "    var_means = var_weights.mean(axis=0)\n",
    "\n",
    "    # Location of mean for observation\n",
    "    mean_loc = np.dot(var_means, test_observation)\n",
    "    \n",
    "    # Estimates of grade\n",
    "    estimates = np.random.normal(loc = mean_loc, scale = sd_value,\n",
    "                                 size = 1000)\n",
    "\n",
    "    # Plot all the estimates\n",
    "    plt.figure(figsize(8, 8))\n",
    "    sns.distplot(estimates, hist = True, kde = True, bins = 19,\n",
    "                 hist_kws = {'edgecolor': 'k', 'color': 'darkblue'},\n",
    "                kde_kws = {'linewidth' : 4},\n",
    "                label = 'Estimated Dist.')\n",
    "    # Plot the actual grade\n",
    "    plt.vlines(x = actual, ymin = 0, ymax = 5, \n",
    "               linestyles = '--', colors = 'red',\n",
    "               label = 'True Grade',\n",
    "              linewidth = 2.5)\n",
    "    \n",
    "    # Plot the mean estimate\n",
    "    plt.vlines(x = mean_loc, ymin = 0, ymax = 5, \n",
    "               linestyles = '-', colors = 'orange',\n",
    "               label = 'Mean Estimate',\n",
    "              linewidth = 2.5)\n",
    "    \n",
    "    plt.legend(loc = 1)\n",
    "    plt.title('Density Plot for Test Observation');\n",
    "    plt.xlabel('Grade'); plt.ylabel('Density');\n",
    "    \n",
    "    # Prediction information\n",
    "    print('True Grade = %d' % actual)\n",
    "    print('Average Estimate = %0.4f' % mean_loc)\n",
    "    print('5%% Estimate = %0.4f    95%% Estimate = %0.4f' % (np.percentile(estimates, 5),\n",
    "                                       np.percentile(estimates, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(normal_trace, X_test.iloc[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(normal_trace, X_test.iloc[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions for New Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for a new data point from the model trace\n",
    "def query_model(trace, new_observation):\n",
    "    \n",
    "    # Print information about the new observation\n",
    "    print('New Observation')\n",
    "    print(new_observation)\n",
    "    # Dictionary of all sampled values for each parameter\n",
    "    var_dict = {}\n",
    "    for variable in trace.varnames:\n",
    "        var_dict[variable] = trace[variable]\n",
    "        \n",
    "    # Standard deviation\n",
    "    sd_value = var_dict['sd'].mean()\n",
    "    \n",
    "    # Results into a dataframe\n",
    "    var_weights = pd.DataFrame(var_dict)\n",
    "    \n",
    "    # Align weights and new observation\n",
    "    var_weights = var_weights[new_observation.index]\n",
    "    \n",
    "    # Means of variables\n",
    "    var_means = var_weights.mean(axis=0)\n",
    "    \n",
    "    # Mean for observation\n",
    "    mean_loc = np.dot(var_means, new_observation)\n",
    "    \n",
    "    # Distribution of estimates\n",
    "    estimates = np.random.normal(loc = mean_loc, scale = sd_value,\n",
    "                                 size = 1000)\n",
    "    \n",
    "    # Plot the estimate distribution\n",
    "    plt.figure(figsize(8, 8))\n",
    "    sns.distplot(estimates, hist = True, kde = True, bins = 19,\n",
    "                 hist_kws = {'edgecolor': 'k', 'color': 'darkblue'},\n",
    "                kde_kws = {'linewidth' : 4},\n",
    "                label = 'Estimated Dist.')\n",
    "    # Plot the mean estimate\n",
    "    plt.vlines(x = mean_loc, ymin = 0, ymax = 5, \n",
    "               linestyles = '-', colors = 'orange', linewidth = 2.5)\n",
    "    plt.title('Density Plot for New Observation');\n",
    "    plt.xlabel('Grade'); plt.ylabel('Density');\n",
    "    \n",
    "    # Estimate information\n",
    "    print('Average Estimate = %0.4f' % mean_loc)\n",
    "    print('5%% Estimate = %0.4f    95%% Estimate = %0.4f' % (np.percentile(estimates, 5),\n",
    "                                       np.percentile(estimates, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = pd.Series({'Intercept': 1, 'mother_edu': 4, 'failures': 0, \n",
    "                            'higher_edu': 1, 'studytime': 3,\n",
    "                            'father_edu': 1, 'absences': 1})\n",
    "query_model(normal_trace, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = pd.Series({'Intercept': 1, 'mother_edu': 2, 'failures': 2, \n",
    "                            'higher_edu': 1, 'studytime': 2,\n",
    "                            'father_edu': 3, 'absences': 4})\n",
    "query_model(normal_trace, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Variable Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the effect of changing one variable while holding the others constant, we can use the function `pm.plot_posterior_predictive_glm`. This takes a range of values to use for the variable, a linear model, and a number of samples. The function evaluates the linear model across the range of values for the number of samples. Each time, it draws a different set of parameters from the trace. This gives us an indication of the effect of a single variable and also the uncertainty in the model estimates. To see the effect of a single variable, we hold the others constant at their median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examines the effect of changing a single variable\n",
    "# Takes in the name of the variable, the trace, and the data\n",
    "def model_effect(query_var, trace, X):\n",
    "    \n",
    "    # Variables that do not change\n",
    "    steady_vars = list(X.columns)\n",
    "    steady_vars.remove(query_var)\n",
    "    \n",
    "    # Linear Model that estimates a grade based on the value of the query variable \n",
    "    # and one sample from the trace\n",
    "    def lm(value, sample):\n",
    "        \n",
    "        # Prediction is the estimate given a value of the query variable\n",
    "        prediction = sample['Intercept'] + sample[query_var] * value\n",
    "        \n",
    "        # Each non-query variable is assumed to be at the median value\n",
    "        for var in steady_vars:\n",
    "            \n",
    "            # Multiply the weight by the median value of the variable\n",
    "            prediction += sample[var] * X[var].median()\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    figsize(6, 6)\n",
    "    \n",
    "    # Find the minimum and maximum values for the range of the query var\n",
    "    var_min = X[query_var].min()\n",
    "    var_max = X[query_var].max()\n",
    "    \n",
    "    # Plot the estimated grade versus the range of query variable\n",
    "    pm.plot_posterior_predictive_glm(trace, eval=np.linspace(var_min, var_max, 100), \n",
    "                                     lm=lm, samples=100, color='blue', \n",
    "                                     alpha = 0.4, lw = 2)\n",
    "    \n",
    "    # Plot formatting\n",
    "    plt.xlabel('%s' % query_var, size = 16)\n",
    "    plt.ylabel('Grade', size = 16)\n",
    "    plt.title(\"Posterior of Grade vs %s\" % query_var, size = 18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effect('mother_edu', normal_trace, X_train.drop(columns='Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effect('studytime', normal_trace, X_train.drop(columns='Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effect('absences', normal_trace, X_train.drop(columns='Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effect('failures', normal_trace, X_train.drop(columns='Grade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effect('father_edu', normal_trace, X_train.drop(columns='Grade'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Likelihood Prior Distribution\n",
    "\n",
    "We can perform the exact same Bayesian Linear Modeling using a Student's T-distribution as the prior for the data likelihood. A Student's T Distribution has more weight in the tails of the distribution so it is more robust to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X values for plotting\n",
    "x = np.linspace(-5, 5, num = 500)\n",
    "\n",
    "# Generate pdf of normal distribution\n",
    "y_norm = scipy.stats.norm.pdf(x)\n",
    "\n",
    "# PDF of t-distribution with 2 degrees of freedom\n",
    "y_t = scipy.stats.t.pdf(x, df = 2)\n",
    "\n",
    "plt.plot(x, y_norm, 'b-', label = 'Normal')\n",
    "plt.plot(x, y_t, 'r-', label = 'T with 2 df')\n",
    "plt.legend(prop = {'size': 18}, loc = 1)\n",
    "plt.xlabel('x'); plt.ylabel('Probability'); plt.title('Normal vs T Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context for model\n",
    "with pm.Model() as t_model:\n",
    "    # Family is Student's T in this case\n",
    "    family = pm.glm.families.StudentT(df = 2)\n",
    "    \n",
    "    # Formula, data, family\n",
    "    pm.GLM.from_formula(formula, data = X_train, family = family)\n",
    "    \n",
    "    # Sample from the posterior \n",
    "    t_trace = pm.sample(draws=2000, tune=500, njobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trace(t_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "__I'm not sure I implemented this part correclty!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_t(trace, test_observation):\n",
    "    \n",
    "    var_dict = {}\n",
    "    for variable in trace.varnames:\n",
    "        var_dict[variable] = trace[variable]\n",
    "\n",
    "    # Results into a dataframe\n",
    "    var_weights = pd.DataFrame(var_dict)\n",
    "\n",
    "    # Actual Value\n",
    "    actual = test_observation['Grade']\n",
    "    \n",
    "    # Add in intercept term\n",
    "    test_observation['Intercept'] = 1\n",
    "    test_observation = test_observation.drop('Grade')\n",
    "    \n",
    "    # Align weights and test observation\n",
    "    var_weights = var_weights[test_observation.index]\n",
    "\n",
    "    # Means for all the weights\n",
    "    var_means = var_weights.mean(axis=0)\n",
    "\n",
    "    # Location of mean for observation\n",
    "    mean_loc = np.dot(var_means, test_observation)\n",
    "    \n",
    "    # Estimates of grade\n",
    "    estimates = mean_loc + np.random.standard_t(df = 2, size = 1000)\n",
    "\n",
    "    plt.figure(figsize(8, 8))\n",
    "    sns.distplot(estimates, hist = True, kde = True, bins = 19,\n",
    "                 hist_kws = {'edgecolor': 'k', 'color': 'darkblue'},\n",
    "                kde_kws = {'linewidth' : 4},\n",
    "                label = 'Estimated Dist.')\n",
    "    plt.vlines(x = actual, ymin = 0, ymax = 5, \n",
    "               linestyles = '--', colors = 'red',\n",
    "               label = 'True Grade',\n",
    "              linewidth = 2.5)\n",
    "    plt.vlines(x = mean_loc, ymin = 0, ymax = 5, \n",
    "               linestyles = '-', colors = 'orange',\n",
    "               label = 'Mean Estimate',\n",
    "              linewidth = 2.5)\n",
    "    \n",
    "    plt.legend(loc = 1)\n",
    "    plt.title('Density Plot for Test Observation');\n",
    "    plt.xlabel('Grade'); plt.ylabel('Density');\n",
    "    \n",
    "    print('True Grade = %d' % actual)\n",
    "    print('Average Estimate = %0.4f' % mean_loc)\n",
    "    print('5%% Estimate = %0.4f    95%% Estimate = %0.4f' % (np.percentile(estimates, 5),\n",
    "                                       np.percentile(estimates, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_t(t_trace, X_test.iloc[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(normal_trace, X_test.iloc[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Observation Predictions\n",
    "\n",
    "__I'm not sure about these predictions!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model_t(trace, new_observation):\n",
    "    \n",
    "    # Dictionary of all sampled values for each parameter\n",
    "    var_dict = {}\n",
    "    for variable in trace.varnames:\n",
    "        var_dict[variable] = trace[variable]\n",
    "        \n",
    "\n",
    "    \n",
    "    # Results into a dataframe\n",
    "    var_weights = pd.DataFrame(var_dict)\n",
    "    \n",
    "    # Align weights and new observation\n",
    "    var_weights = var_weights[new_observation.index]\n",
    "    # Means of variables\n",
    "    var_means = var_weights.mean(axis=0)\n",
    "    \n",
    "    # Mean for observation\n",
    "    mean_loc = np.dot(var_means, new_observation)\n",
    "    \n",
    "    # Distribution of estimates\n",
    "    estimates = mean_loc +  np.random.standard_t(df = 2, size = 1000)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize(8, 8))\n",
    "    sns.distplot(estimates, hist = True, kde = True, bins = 19,\n",
    "                 hist_kws = {'edgecolor': 'k', 'color': 'darkblue'},\n",
    "                kde_kws = {'linewidth' : 4},\n",
    "                label = 'Estimated Dist.')\n",
    "    plt.vlines(x = mean_loc, ymin = 0, ymax = 5, \n",
    "               linestyles = '-', colors = 'orange', linewidth = 2.5)\n",
    "    plt.title('Density Plot for New Observation');\n",
    "    plt.xlabel('Grade'); plt.ylabel('Density');\n",
    "    \n",
    "    print('Average Estimate = %0.4f' % mean_loc)\n",
    "    print('5%% Estimate = %0.4f    95%% Estimate = %0.4f' % (np.percentile(estimates, 5),\n",
    "                                       np.percentile(estimates, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = pd.Series({'Intercept': 1, 'mother_edu': 4, 'failures': 0, \n",
    "                            'higher_edu': 1, 'studytime': 3,\n",
    "                            'father_edu': 1, 'absences': 1})\n",
    "query_model(normal_trace, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = pd.Series({'Intercept': 1, 'mother_edu': 4, 'failures': 0, \n",
    "                            'higher_edu': 1, 'studytime': 3,\n",
    "                            'father_edu': 1, 'absences': 1})\n",
    "query_model_t(t_trace, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some variation between the t-distribution estimates and those from the normal distribution for the data likelihood.Choosing appropriate priors is one of the hardest aspect of Bayesian Modeling, but we can get around that by having more data. As the amount of data the model learns from increases, the prior has less of an effect because each time the posterior is updated based on the new data. Essentially machine learning models perform inference with no priors, basing the final model entirely on the data. In the case of limited samples, Bayesian Inference can be a better method for building models because it provides a reasonable estimate in situations with few data points (as long as the prior is reasonable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook we looked at using Bayesian Linear Regression to predict student performance based on six factors. Rather than specify probabilities for the Bayesian network which is basically impossible for continuous variables, we framed the problem as a machine learning task. In addition to the standard machine learning models that learn from observations, we also used Bayesian Linear Regression to create a model mapping the features (student characteristics) to the targets (final grade). The advantages of Bayesian Linear Regression are that if we use sensible priors, we can still get a decent estimate with few samples, and the final weights are not a single number, but a distribution componsed of every sample drawn during the sampling run. We can then make predictions using all the sampled weights to form a distribution of expected values rather than a single answer. \n",
    "\n",
    "The Bayesian  Linear Regression did not perform as well as the other methods in terms of the two metrics we choose. This might not be the ideal case for a Bayesian inference approach but we saw that Bayesian Linear Regression produced intuitive estimates for the model weights and gave predictions for new students that align with our expectations for the factors influencing student performance. To summarize, although Bayesian Linear Regression did not outperform the standard machine learning methods, it gave us a chance to learn another tool for use in evaluating and making sense of data. It's always a positive to have more skills that you can deploy as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
